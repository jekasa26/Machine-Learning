{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB 2, Exercise6\n",
    "\n",
    "D. Shahrokhian https://stackabuse.com/the-naive-bayes-algorithm-in-python-with-scikit-learn/\n",
    "In [1]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading base Biggie_lyrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "biggie_df = pd.read_csv('./biggie_lyrics.csv', usecols=[1], encoding='latin-1', header=None)\n",
    "\n",
    "\n",
    "#Reading Base 2pac \n",
    "pac_df = pd.read_csv('./2pac_lyrics.csv', usecols=[1], encoding='latin-1', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i aint got no motherfucking friends\\nthats why...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>troublesome nigga\\nhahaha troublesome 19mother...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>change shit\\ni guess change is good for any of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i see no changes wake up in the morning and i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>out on bail fresh out of jail california dream...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lyrics\n",
       "11  i aint got no motherfucking friends\\nthats why...\n",
       "12  troublesome nigga\\nhahaha troublesome 19mother...\n",
       "13  change shit\\ni guess change is good for any of...\n",
       "14  i see no changes wake up in the morning and i ...\n",
       "15  out on bail fresh out of jail california dream..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Preprocessing Biggie_lyrics\n",
    "biggie_df.columns = [\"lyrics\"]\n",
    "biggie_df[\"lyrics\"] = biggie_df[\"lyrics\"].str.replace('[^\\w\\s]','')\n",
    "biggie_df[\"lyrics\"] = biggie_df[\"lyrics\"].str.lower()\n",
    "biggie_df.tail()\n",
    "\n",
    "#Preprocessing Base 2pac \n",
    "pac_df.columns = [\"lyrics\"]\n",
    "pac_df[\"lyrics\"] = pac_df[\"lyrics\"].str.replace('[^\\w\\s]','')\n",
    "pac_df[\"lyrics\"] = pac_df[\"lyrics\"].str.lower()\n",
    "pac_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               line\n",
      "0      0                                  fuck all you hoes\n",
      "1      0                            get a grip motherfucker\n",
      "2      0  yeah this album is dedicated to all the teache...\n",
      "3      0  id never amount to nothin to all the people th...\n",
      "4      0  buildings that i was hustlin in front of that ...\n"
     ]
    }
   ],
   "source": [
    "biggie_lyrics = biggie_df[\"lyrics\"].values\n",
    "biggie_lyrics = [ song.split('\\n') for song in biggie_lyrics]\n",
    "biggie_lyrics = [line for song in biggie_lyrics for line in song]\n",
    "pac_lyrics = pac_df[\"lyrics\"].values\n",
    "pac_lyrics = [ song.split('\\n') for song in pac_lyrics]\n",
    "pac_lyrics = [line for song in pac_lyrics for line in song]\n",
    "\n",
    "rap_lines = [] \n",
    "\n",
    "for line in biggie_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([0,str(line)]))\n",
    "        \n",
    "for line in pac_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([1,str(line)]))\n",
    "        \n",
    "rap_lines = np.array(rap_lines)\n",
    "\n",
    "rap_lines = pd.DataFrame(rap_lines)\n",
    "rap_lines.columns = [\"label\",\"line\"]\n",
    "rap_lines['label'] = rap_lines['label'].replace(['0','1'],[0,1])\n",
    "print(rap_lines.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jessicasalas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "      label                                               line\n",
      "0         0                             [fuck, all, you, hoes]\n",
      "1         0                       [get, a, grip, motherfucker]\n",
      "2         0  [yeah, this, album, is, dedicated, to, all, th...\n",
      "3         0  [id, never, amount, to, nothin, to, all, the, ...\n",
      "4         0  [buildings, that, i, was, hustlin, in, front, ...\n",
      "5         0  [me, when, i, was, just, tryin, to, make, some...\n",
      "6         0  [and, all, the, niggas, in, the, struggle, you...\n",
      "7         0           [uhha, its, all, good, baby, baybee, uh]\n",
      "8         0                           [it, was, all, a, dream]\n",
      "9         0            [i, used, to, read, word, up, magazine]\n",
      "10        0  [saltnpepa, and, heavy, d, up, in, the, limous...\n",
      "11        0                   [hangin, pictures, on, my, wall]\n",
      "12        0  [every, saturday, rap, attack, mr, magic, marl...\n",
      "13        0       [i, let, my, tape, rock, til, my, tape, pop]\n",
      "14        0  [smokin, weed, and, bamboo, sippin, on, privat...\n",
      "15        0  [way, back, when, i, had, the, red, and, black...\n",
      "16        0                        [with, the, hat, to, match]\n",
      "17        0             [remember, rappin, duke, duhha, duhha]\n",
      "18        0  [you, never, thought, that, hip, hop, would, t...\n",
      "19        0  [now, im, in, the, limelight, cause, i, rhyme,...\n",
      "20        0  [time, to, get, paid, blow, up, like, the, wor...\n",
      "21        0       [born, sinner, the, opposite, of, a, winner]\n",
      "22        0  [remember, when, i, used, to, eat, sardines, f...\n",
      "23        0         [peace, to, ron, g, brucey, b, kid, capri]\n",
      "24        0               [funkmaster, flex, lovebug, starsky]\n",
      "25        0     [im, blowin, up, like, you, thought, i, would]\n",
      "26        0        [call, the, crib, same, number, same, hood]\n",
      "27        0  [uh, and, if, you, dont, know, now, you, know,...\n",
      "28        0             [you, know, very, well, who, you, are]\n",
      "29        0  [dont, let, em, hold, you, down, reach, for, t...\n",
      "...     ...                                                ...\n",
      "1940      1      [dont, let, em, jack, you, up, back, you, up]\n",
      "1941      1          [crack, you, up, and, pimpsmack, you, up]\n",
      "1942      1         [you, got, ta, learn, to, hold, your, own]\n",
      "1943      1  [they, get, jealous, when, they, see, you, wit...\n",
      "1944      1    [but, tell, the, cops, they, cant, touch, this]\n",
      "1945      1  [i, dont, trust, this, when, they, try, to, ru...\n",
      "1946      1                  [thats, the, sound, of, my, tool]\n",
      "1947      1  [you, say, it, aint, cool, my, mama, didnt, ra...\n",
      "1948      1  [and, as, long, as, i, stay, black, i, got, ta...\n",
      "1949      1                [and, i, never, get, to, lay, back]\n",
      "1950      1  [cause, i, always, got, to, worry, bout, the, ...\n",
      "1951      1      [some, buck, that, i, roughed, up, way, back]\n",
      "1952      1           [coming, back, after, all, these, years]\n",
      "1953      1        [ratatattattattat, thats, the, way, it, is]\n",
      "1954      1  [out, on, bail, fresh, out, of, jail, californ...\n",
      "1955      1  [soon, as, i, step, on, the, scene, im, hearin...\n",
      "1956      1               [fiending, for, money, and, alcohol]\n",
      "1957      1  [the, life, of, a, westside, player, where, co...\n",
      "1958      1  [only, in, cali, where, we, riot, not, rally, ...\n",
      "1959      1  [in, la, we, wearing, chucks, not, ballys, yea...\n",
      "1960      1  [dressed, in, locs, and, khaki, suits, and, ri...\n",
      "1961      1  [flossing, but, have, caution, we, collide, wi...\n",
      "1962      1                     [famous, because, we, program]\n",
      "1963      1  [worldwide, let, them, recognize, from, long, ...\n",
      "1964      1  [bumping, and, grinding, like, a, slow, jam, i...\n",
      "1965      1  [so, you, know, the, row, wont, bow, down, to,...\n",
      "1966      1  [say, what, you, say, but, give, me, that, bom...\n",
      "1967      1          [let, me, serenade, the, streets, of, la]\n",
      "1968      1  [from, oakland, to, sactown, the, bay, area, a...\n",
      "1969      1    [cali, is, where, they, put, their, mack, down]\n",
      "\n",
      "[1970 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')\n",
    "#Preprocessing Biggie_lyrics\n",
    "\n",
    "rap_lines[\"line\"] = rap_lines[\"line\"].apply(nltk.word_tokenize)\n",
    "print(rap_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                [fuck, all, you, hoe]\n",
       "1                           [get, a, grip, motherfuck]\n",
       "2    [yeah, thi, album, is, dedic, to, all, the, te...\n",
       "3    [id, never, amount, to, nothin, to, all, the, ...\n",
       "4    [build, that, i, wa, hustlin, in, front, of, t...\n",
       "Name: line, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.nltk.org/api/nltk.stem.html\n",
    "#https://tartarus.org/martin/PorterStemmer/\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "rap_lines[\"line\"] = rap_lines[\"line\"].apply(lambda x: [stemmer.stem(y) for y in x]) \n",
    "rap_lines[\"line\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     fuck all you hoe\n",
       "1                                get a grip motherfuck\n",
       "2    yeah thi album is dedic to all the teacher tha...\n",
       "3    id never amount to nothin to all the peopl tha...\n",
       "4    build that i wa hustlin in front of that call ...\n",
       "Name: line, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts the list of words into space-separated strings\n",
    "rap_lines[\"line\"] = rap_lines[\"line\"].apply(lambda x: ' '.join(x))\n",
    "rap_lines[\"line\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1038)\t1\n",
      "  (0, 2519)\t1\n",
      "  (0, 63)\t1\n",
      "  (0, 859)\t1\n",
      "  (1, 1443)\t1\n",
      "  (1, 943)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 888)\t1\n",
      "  (2, 1371)\t1\n",
      "  (2, 2278)\t1\n",
      "  (2, 2217)\t1\n",
      "  (2, 2192)\t1\n",
      "  (2, 2220)\t1\n",
      "  (2, 2272)\t1\n",
      "  (2, 569)\t1\n",
      "  (2, 1143)\t1\n",
      "  (2, 58)\t1\n",
      "  (2, 2232)\t1\n",
      "  (2, 2511)\t1\n",
      "  (2, 63)\t1\n",
      "  (3, 24)\t1\n",
      "  (3, 1283)\t1\n",
      "  (3, 1609)\t1\n",
      "  (3, 1515)\t1\n",
      "  (3, 80)\t1\n",
      "  :\t:\n",
      "  (1967, 1909)\t1\n",
      "  (1967, 1213)\t1\n",
      "  (1967, 2118)\t1\n",
      "  (1967, 1253)\t1\n",
      "  (1967, 1531)\t1\n",
      "  (1967, 1371)\t1\n",
      "  (1967, 2220)\t1\n",
      "  (1968, 97)\t1\n",
      "  (1968, 149)\t1\n",
      "  (1968, 1848)\t1\n",
      "  (1968, 1527)\t1\n",
      "  (1968, 856)\t1\n",
      "  (1968, 642)\t1\n",
      "  (1968, 124)\t1\n",
      "  (1968, 83)\t1\n",
      "  (1968, 2220)\t1\n",
      "  (1968, 2272)\t1\n",
      "  (1969, 328)\t1\n",
      "  (1969, 2222)\t1\n",
      "  (1969, 1327)\t1\n",
      "  (1969, 2446)\t1\n",
      "  (1969, 1718)\t1\n",
      "  (1969, 2228)\t1\n",
      "  (1969, 642)\t1\n",
      "  (1969, 1143)\t1\n",
      "(1970, 2535)\n"
     ]
    }
   ],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "# to allow one letter words count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\") \n",
    "counts = count_vect.fit_transform(rap_lines[\"line\"])  \n",
    "print(counts)\n",
    "print(counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725    1\n",
      "176     0\n",
      "750     0\n",
      "39      0\n",
      "421     0\n",
      "558     0\n",
      "1168    1\n",
      "264     0\n",
      "876     1\n",
      "908     1\n",
      "1581    1\n",
      "1288    1\n",
      "602     0\n",
      "1452    1\n",
      "354     0\n",
      "11      0\n",
      "929     1\n",
      "741     0\n",
      "826     0\n",
      "855     0\n",
      "1473    1\n",
      "1571    1\n",
      "984     1\n",
      "1697    1\n",
      "1136    1\n",
      "947     1\n",
      "642     0\n",
      "1921    1\n",
      "800     0\n",
      "1917    1\n",
      "       ..\n",
      "1698    1\n",
      "1674    1\n",
      "1375    1\n",
      "935     1\n",
      "425     0\n",
      "1472    1\n",
      "433     0\n",
      "1537    1\n",
      "685     0\n",
      "1877    1\n",
      "335     0\n",
      "1759    1\n",
      "1516    1\n",
      "373     0\n",
      "428     0\n",
      "1968    1\n",
      "1460    1\n",
      "532     0\n",
      "227     0\n",
      "1028    1\n",
      "1269    1\n",
      "58      0\n",
      "248     0\n",
      "1030    1\n",
      "1682    1\n",
      "1846    1\n",
      "780     0\n",
      "752     0\n",
      "1244    1\n",
      "304     0\n",
      "Name: label, Length: 197, dtype: int64\n",
      "  (0, 19)\t1\n",
      "  (0, 1371)\t1\n",
      "  (0, 1214)\t1\n",
      "  (0, 2421)\t1\n",
      "  (0, 1385)\t1\n",
      "  (0, 1390)\t1\n",
      "  (0, 1254)\t1\n",
      "  (1, 2393)\t1\n",
      "  (1, 2441)\t1\n",
      "  (1, 2456)\t1\n",
      "  (1, 2019)\t1\n",
      "  (1, 2073)\t1\n",
      "  (1, 925)\t1\n",
      "  (1, 1888)\t1\n",
      "  (1, 1837)\t1\n",
      "  (2, 1096)\t1\n",
      "  (2, 123)\t1\n",
      "  (2, 1269)\t1\n",
      "  (2, 300)\t2\n",
      "  (2, 612)\t1\n",
      "  (2, 1122)\t1\n",
      "  (3, 2232)\t1\n",
      "  (3, 1482)\t1\n",
      "  (3, 1096)\t1\n",
      "  (3, 1144)\t1\n",
      "  :\t:\n",
      "  (193, 2291)\t1\n",
      "  (193, 409)\t1\n",
      "  (194, 1436)\t1\n",
      "  (194, 2213)\t1\n",
      "  (194, 1979)\t1\n",
      "  (194, 1602)\t1\n",
      "  (194, 1102)\t1\n",
      "  (194, 1670)\t1\n",
      "  (195, 2232)\t1\n",
      "  (195, 1283)\t1\n",
      "  (195, 1096)\t1\n",
      "  (195, 1114)\t1\n",
      "  (195, 1462)\t1\n",
      "  (195, 2266)\t1\n",
      "  (195, 2434)\t1\n",
      "  (195, 366)\t1\n",
      "  (195, 52)\t1\n",
      "  (195, 2062)\t1\n",
      "  (196, 1108)\t1\n",
      "  (196, 2020)\t1\n",
      "  (196, 1519)\t1\n",
      "  (196, 1342)\t1\n",
      "  (196, 219)\t1\n",
      "  (196, 511)\t1\n",
      "  (196, 2240)\t1\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, rap_lines[\"label\"], test_size=0.1, random_state=69)\n",
    "print(y_test)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is : 0.7177664975\n",
      "[[232 208]\n",
      " [ 70 475]]\n"
     ]
    }
   ],
   "source": [
    "#Ajustar los datos al modelo \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "#Evaluar  el modelo \n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "print(\"The accuracy is : %.10f\" % np.mean(predicted == y_test))\n",
    "#Evaluemos la matriz de precisi√≥n \n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predicted))  \n",
    "yprob = model.predict_proba(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONS:\n",
    "\n",
    "Comparing the results from N Lidellwith with this code, we can see the accuracy is better in this notebook than the previous notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766497461928934\n",
      "[[119  50]\n",
      " [ 42 183]]\n",
      "0.7131979695431472\n",
      "[[ 95  70]\n",
      " [ 43 186]]\n",
      "0.7157360406091371\n",
      "[[110  77]\n",
      " [ 35 172]]\n",
      "0.6903553299492385\n",
      "[[105  89]\n",
      " [ 33 167]]\n",
      "0.7055837563451777\n",
      "[[109  82]\n",
      " [ 34 169]]\n",
      "average perfromance\n",
      "0.7182741116751268\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, rap_lines[\"label\"], test_size=0.2) \n",
    "    model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "\n",
    "print (\"average perfromance\")\n",
    "print (per/5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716751269035533\n",
      "[[231 216]\n",
      " [ 63 475]]\n",
      "0.6873096446700507\n",
      "[[206 228]\n",
      " [ 80 471]]\n",
      "0.7076142131979696\n",
      "[[238 205]\n",
      " [ 83 459]]\n",
      "0.7025380710659899\n",
      "[[227 195]\n",
      " [ 98 465]]\n",
      "0.7177664974619289\n",
      "[[232 208]\n",
      " [ 70 475]]\n",
      "average perfromance\n",
      "0.7063959390862944\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, rap_lines[\"label\"], test_size=0.5) \n",
    "    model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print (\"average perfromance\")\n",
    "print (per/5.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
