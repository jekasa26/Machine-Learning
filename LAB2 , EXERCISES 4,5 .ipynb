{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2 \n",
    "\n",
    "### SPAM Detection - The Naive Bayes Algorithm in Python with Scikit-Learn \n",
    "D. Shahrokhian\n",
    "https://stackabuse.com/the-naive-bayes-algorithm-in-python-with-scikit-learn/\n",
    "\n",
    "4. Use the data in Tables 13.1  and 13.10  from [1]  and the Naive Bayes for Spam Detection from IAML Edimburg with the D. Shahrokhian code â€“ Quantopian and  Github.  Why are the probabilities obtained with the predict_proba from sklearn different of the probabilities obtained by hand and with the N Lidell code?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****READING TABLE 13.1******\n",
      "  label                              message\n",
      "0   yes              Chinese Beijing Chinese\n",
      "1   yes             Chinese Chinese Shanghai\n",
      "2   yes                        Chinese Macao\n",
      "3    no                  Tokyo Japan Chinese\n",
      "4   yes  Chinese Chinese Chinese Tokyo Japan\n",
      "*****READING TABLE 13.10******\n",
      "  label                message\n",
      "0   yes         Taipei Taiwan \n",
      "1   yes  Macao Taiwan Shanghai\n",
      "2    no           apan Sapporo\n",
      "3    no   Sapporo Osaka Taiwan\n",
      "4    no  Taiwan Taiwan Sapporo\n",
      "******READING Table IAM******\n",
      "  label                message\n",
      "0  spam  send us your password\n",
      "1   ham    send us your review\n",
      "2   ham   review your password\n",
      "3  spam              review us\n",
      "4  spam     send your password\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Tabla 13.1 \n",
    "print(\"*****READING TABLE 13.1******\")\n",
    "\n",
    "\n",
    "df1 = pd.read_table('Tabla13.1',  \n",
    "                   sep='\\t', \n",
    "                   header= None ,\n",
    "                   names=['label', 'message'])\n",
    "print(df1.head())\n",
    "\n",
    "#Tabla 13.10\n",
    "print(\"*****READING TABLE 13.10******\")\n",
    "\n",
    "df10 = pd.read_table('Tabla13.10',  \n",
    "                   sep='\\t', \n",
    "                   header= None ,\n",
    "                   names=['label', 'message'])\n",
    "print(df10.head())\n",
    "\n",
    "print(\"******READING Table IAM******\")\n",
    "\n",
    "\n",
    "#Tabla IAM\n",
    "\n",
    "df2 = pd.read_table('IAM',  \n",
    "                   sep='\\t', \n",
    "                   header= None ,\n",
    "                   names=['label', 'message'])\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Table 13.1******\n",
      "   label                              message\n",
      "0      1              chinese beijing chinese\n",
      "1      1             chinese chinese shanghai\n",
      "2      1                        chinese macao\n",
      "3      0                  tokyo japan chinese\n",
      "4      1  chinese chinese chinese tokyo japan\n",
      "*****Table 13.10******\n",
      "   label                message\n",
      "0      1         taipei taiwan \n",
      "1      1  macao taiwan shanghai\n",
      "2      0           apan sapporo\n",
      "3      0   sapporo osaka taiwan\n",
      "4      0  taiwan taiwan sapporo\n",
      "******Table IAM******\n",
      "   label                message\n",
      "0      1  send us your password\n",
      "1      0    send us your review\n",
      "2      0   review your password\n",
      "3      1              review us\n",
      "4      1     send your password\n"
     ]
    }
   ],
   "source": [
    "print(\"*****Table 13.1******\")\n",
    "df1['label'] = df1.label.map({'yes': 1, 'no': 0})\n",
    "df1['message'] = df1.message.map(lambda x: x.lower())\n",
    "print(df1.head())\n",
    "\n",
    "print(\"*****Table 13.10******\")\n",
    "df10['label'] = df10.label.map({'yes': 1, 'no': 0})\n",
    "df10['message'] = df10.message.map(lambda x: x.lower())\n",
    "print(df10.head())\n",
    "\n",
    "print(\"******Table IAM******\")\n",
    "df2['label'] = df2.label.map({'spam': 1, 'ham': 0})\n",
    "df2['message'] = df2.message.map(lambda x: x.lower())\n",
    "print(df2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jessicasalas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "*****Table 13.1******\n",
      "   label                                    message\n",
      "0      1                [chinese, beijing, chinese]\n",
      "1      1               [chinese, chinese, shanghai]\n",
      "2      1                           [chinese, macao]\n",
      "3      0                    [tokyo, japan, chinese]\n",
      "4      1  [chinese, chinese, chinese, tokyo, japan]\n",
      "*****Table 13.10******\n",
      "   label                    message\n",
      "0      1           [taipei, taiwan]\n",
      "1      1  [macao, taiwan, shanghai]\n",
      "2      0            [apan, sapporo]\n",
      "3      0   [sapporo, osaka, taiwan]\n",
      "4      0  [taiwan, taiwan, sapporo]\n",
      "******Table IAM******\n",
      "   label                     message\n",
      "0      1  [send, us, your, password]\n",
      "1      0    [send, us, your, review]\n",
      "2      0    [review, your, password]\n",
      "3      1                [review, us]\n",
      "4      1      [send, your, password]\n"
     ]
    }
   ],
   "source": [
    "# https://www.nltk.org/ Natural Language Toolkit\n",
    "# Punkt Sentence Tokenizer https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "print(\"*****Table 13.1******\")\n",
    "df1['message'] = df1['message'].apply(nltk.word_tokenize)\n",
    "print(df1.head())\n",
    "\n",
    "print(\"*****Table 13.10******\")\n",
    "df10['message'] = df10['message'].apply(nltk.word_tokenize)\n",
    "print(df10.head())\n",
    "\n",
    "print(\"******Table IAM******\")\n",
    "df2['message'] = df2['message'].apply(nltk.word_tokenize)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Table 13.1******\n",
      "   label                                 message\n",
      "0      1                  [chines, beij, chines]\n",
      "1      1              [chines, chines, shanghai]\n",
      "2      1                         [chines, macao]\n",
      "3      0                  [tokyo, japan, chines]\n",
      "4      1  [chines, chines, chines, tokyo, japan]\n",
      "*****Table 13.10******\n",
      "   label                    message\n",
      "0      1           [taipei, taiwan]\n",
      "1      1  [macao, taiwan, shanghai]\n",
      "2      0            [apan, sapporo]\n",
      "3      0   [sapporo, osaka, taiwan]\n",
      "4      0  [taiwan, taiwan, sapporo]\n",
      "******Table IAM******\n",
      "   label                     message\n",
      "0      1  [send, us, your, password]\n",
      "1      0    [send, us, your, review]\n",
      "2      0    [review, your, password]\n",
      "3      1                [review, us]\n",
      "4      1      [send, your, password]\n"
     ]
    }
   ],
   "source": [
    "# https://www.nltk.org/api/nltk.stem.html\n",
    "#https://tartarus.org/martin/PorterStemmer/\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print(\"*****Table 13.1******\")\n",
    "df1['message'] = df1['message'].apply(lambda x: [stemmer.stem(y) for y in x]) \n",
    "print(df1.head())\n",
    "\n",
    "print(\"*****Table 13.10******\")\n",
    "df10['message'] = df10['message'].apply(lambda x: [stemmer.stem(y) for y in x]) \n",
    "print(df10.head())\n",
    "\n",
    "print(\"******Table IAM******\")\n",
    "df2['message'] = df2['message'].apply(lambda x: [stemmer.stem(y) for y in x]) \n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Table 13.1******\n",
      "   label                           message\n",
      "0      1                chines beij chines\n",
      "1      1            chines chines shanghai\n",
      "2      1                      chines macao\n",
      "3      0                tokyo japan chines\n",
      "4      1  chines chines chines tokyo japan\n",
      "*****Table 13.10******\n",
      "   label                message\n",
      "0      1          taipei taiwan\n",
      "1      1  macao taiwan shanghai\n",
      "2      0           apan sapporo\n",
      "3      0   sapporo osaka taiwan\n",
      "4      0  taiwan taiwan sapporo\n",
      "******Table IAM******\n",
      "   label                message\n",
      "0      1  send us your password\n",
      "1      0    send us your review\n",
      "2      0   review your password\n",
      "3      1              review us\n",
      "4      1     send your password\n"
     ]
    }
   ],
   "source": [
    "# Converts the list of words into space-separated strings\n",
    "print(\"*****Table 13.1******\")\n",
    "df1['message'] = df1['message'].apply(lambda x: ' '.join(x))\n",
    "print(df1.head())\n",
    "print(\"*****Table 13.10******\")\n",
    "df10['message'] = df10['message'].apply(lambda x: ' '.join(x))\n",
    "print(df10.head())\n",
    "\n",
    "print(\"******Table IAM******\")\n",
    "df2['message'] = df2['message'].apply(lambda x: ' '.join(x))\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Table 13.1******\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t2\n",
      "  (1, 4)\t1\n",
      "  (1, 1)\t2\n",
      "  (2, 3)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 5)\t1\n",
      "  (4, 1)\t3\n",
      "*****Table 13.10******\n",
      "  (0, 6)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 6)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 0)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 6)\t1\n",
      "  (4, 3)\t1\n",
      "  (4, 6)\t2\n",
      "******Table IAM******\n",
      "  (0, 2)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 6)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 5)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 6)\t1\n",
      "  (4, 4)\t1\n",
      "  (5, 0)\t1\n",
      "  (5, 6)\t1\n",
      "  (5, 5)\t1\n",
      "  (5, 4)\t1\n",
      "  (6, 1)\t1\n",
      "  (6, 3)\t1\n",
      "  (6, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "# to allow one letter words count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect1 = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\") \n",
    "counts1 = count_vect1.fit_transform(df1['message'])  \n",
    "print(\"*****Table 13.1******\")\n",
    "print(counts1)\n",
    "\n",
    "count_vect10 = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\") \n",
    "counts10 = count_vect10.fit_transform(df10['message'])  \n",
    "\n",
    "print(\"*****Table 13.10******\")\n",
    "print(counts10)\n",
    "\n",
    "\n",
    "count_vect2 = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\") \n",
    "counts2 = count_vect2.fit_transform(df2['message'])  \n",
    "\n",
    "print(\"******Table IAM******\")\n",
    "print(counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6)\n",
      "(5, 7)\n",
      "(7, 7)\n"
     ]
    }
   ],
   "source": [
    "print(counts1.shape)\n",
    "print(counts10.shape)\n",
    "print(counts2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING MODEL FOR TABLE 13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model for Table 13.1 \n",
      "[[0.31024139 0.68975861]]\n",
      "Accurancy is:\n",
      "1.0\n",
      "The confusion matrix is:\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"The model for Table 13.1 \")\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts1, df1['label'], test_size=0.1, random_state=55, shuffle=False)\n",
    "#Ajustar los datos al modelo \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "#Evaluar  el modelo \n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "probability = model.predict_proba(X_test)\n",
    "print(probability)\n",
    "print('Accurancy is:')\n",
    "print(np.mean(predicted == y_test))\n",
    "#Evaluemos la matriz de confusiÃ³n\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('The confusion matrix is:')\n",
    "print(confusion_matrix(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "0.0\n",
      "[[0 1]\n",
      " [0 0]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "0.0\n",
      "[[0 1]\n",
      " [0 0]]\n",
      "1.0\n",
      "[[1]]\n",
      "(1,)\n",
      "2    1\n",
      "Name: label, dtype: int64\n",
      "average perfromance\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts1, df1['label'], test_size=0.2) \n",
    "    model = MultinomialNB().fit(X_train, y_train) \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print(y_test.shape)\n",
    "print(y_test)\n",
    "print (\"average perfromance\")\n",
    "print (per/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "[[0 0]\n",
      " [1 2]]\n",
      "0.6666666666666666\n",
      "[[0 0]\n",
      " [1 2]]\n",
      "0.6666666666666666\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "0.6666666666666666\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "0.6666666666666666\n",
      "[[0 0]\n",
      " [1 2]]\n",
      "0.6666666666666666\n",
      "[[0 0]\n",
      " [1 2]]\n",
      "0.6666666666666666\n",
      "[[0 0]\n",
      " [1 2]]\n",
      "0.6666666666666666\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "0.6666666666666666\n",
      "[[0 1]\n",
      " [0 2]]\n",
      "0.6666666666666666\n",
      "[[0 0]\n",
      " [1 2]]\n",
      "average perfromance\n",
      "0.6666666666666667\n",
      "2    1\n",
      "4    1\n",
      "1    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts1, df1['label'], test_size=0.5) \n",
    "    model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print (\"average perfromance\")\n",
    "print (per/10.0)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING MODEL FOR TABLE 13.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model for Table 13.10 \n",
      "[[0.57142857 0.42857143]]\n",
      "Accurancy is:\n",
      "1.0\n",
      "The confusion matrix is:\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"The model for Table 13.10 \")\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts10, df10['label'], test_size=0.1, random_state=55, shuffle=False)\n",
    "#Ajustar los datos al modelo \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "#Evaluar  el modelo \n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "probability = model.predict_proba(X_test)\n",
    "print(probability)\n",
    "print('Accurancy is:')\n",
    "print(np.mean(predicted == y_test))\n",
    "#Evaluemos la matriz de confusiÃ³n\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('The confusion matrix is:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "average perfromance\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts10, df10['label'], test_size=0.2) \n",
    "    model = MultinomialNB().fit(X_train, y_train) \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print (\"average perfromance\")\n",
    "print (per/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[[0 3]\n",
      " [0 0]]\n",
      "0.0\n",
      "[[0 3]\n",
      " [0 0]]\n",
      "0.3333333333333333\n",
      "[[1 0]\n",
      " [2 0]]\n",
      "0.0\n",
      "[[0 3]\n",
      " [0 0]]\n",
      "0.6666666666666666\n",
      "[[2 0]\n",
      " [1 0]]\n",
      "0.3333333333333333\n",
      "[[1 0]\n",
      " [2 0]]\n",
      "0.6666666666666666\n",
      "[[1 1]\n",
      " [0 1]]\n",
      "0.3333333333333333\n",
      "[[1 0]\n",
      " [2 0]]\n",
      "0.3333333333333333\n",
      "[[1 0]\n",
      " [2 0]]\n",
      "0.6666666666666666\n",
      "[[2 0]\n",
      " [1 0]]\n",
      "average perfromance\n",
      "0.33333333333333337\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts10, df10['label'], test_size=0.5) \n",
    "    model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print (\"average perfromance\")\n",
    "print (per/10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING MODEL FOR IAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model for Table 13.10 \n",
      "[[0.57142857 0.42857143]]\n",
      "Accurancy is:\n",
      "1.0\n",
      "The confusion matrix is:\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"The model for Table 13.10 \")\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts10, df10['label'], test_size=0.1, random_state=55, shuffle=False)\n",
    "#Ajustar los datos al modelo \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "#Evaluar  el modelo \n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "probability = model.predict_proba(X_test)\n",
    "print(probability)\n",
    "print('Accurancy is:')\n",
    "print(np.mean(predicted == y_test))\n",
    "#Evaluemos la matriz de confusiÃ³n\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('The confusion matrix is:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "average perfromance\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts10, df10['label'], test_size=0.2) \n",
    "    model = MultinomialNB().fit(X_train, y_train) \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print (\"average perfromance\")\n",
    "print (per/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "[[1 1]\n",
      " [0 1]]\n",
      "0.3333333333333333\n",
      "[[1 0]\n",
      " [2 0]]\n",
      "0.6666666666666666\n",
      "[[1 1]\n",
      " [0 1]]\n",
      "0.6666666666666666\n",
      "[[2 0]\n",
      " [1 0]]\n",
      "0.0\n",
      "[[0 3]\n",
      " [0 0]]\n",
      "0.6666666666666666\n",
      "[[2 0]\n",
      " [1 0]]\n",
      "0.3333333333333333\n",
      "[[1 0]\n",
      " [2 0]]\n",
      "0.3333333333333333\n",
      "[[1 0]\n",
      " [2 0]]\n",
      "0.3333333333333333\n",
      "[[1 0]\n",
      " [2 0]]\n",
      "0.6666666666666666\n",
      "[[2 0]\n",
      " [1 0]]\n",
      "average perfromance\n",
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts10, df10['label'], test_size=0.5) \n",
    "    model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print (\"average perfromance\")\n",
    "print (per/10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli NB classifier \n",
    "5. Use the same data in 4 with the D. Shahrokhian code  but using the Bernoulli NB classifier from sklearn and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING MODEL FOR TABLE 13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model for Table 13.1 \n",
      "[[0.80893321 0.19106679]]\n",
      "Accurancy is:\n",
      "0.0\n",
      "The confusion matrix is:\n",
      "[[0 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"The model for Table 13.1 \")\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts1, df1['label'], test_size=0.1, random_state=55, shuffle=False)\n",
    "#Ajustar los datos al modelo \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB().fit(X_train, y_train)\n",
    "#Evaluar  el modelo \n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "probability = model.predict_proba(X_test)\n",
    "print(probability)\n",
    "print('Accurancy is:')\n",
    "print(np.mean(predicted == y_test))\n",
    "#Evaluemos la matriz de confusiÃ³n\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('The confusion matrix is:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING MODEL FOR TABLE 13.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model for Table 13.10 \n",
      "[[0.75 0.25]]\n",
      "Accurancy is:\n",
      "1.0\n",
      "The confusion matrix is:\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"The model for Table 13.10 \")\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts10, df10['label'], test_size=0.1, random_state=55, shuffle=False)\n",
    "#Ajustar los datos al modelo \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB().fit(X_train, y_train)\n",
    "#Evaluar  el modelo \n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "probability = model.predict_proba(X_test)\n",
    "print(probability)\n",
    "print('Accurancy is:')\n",
    "print(np.mean(predicted == y_test))\n",
    "#Evaluemos la matriz de confusiÃ³n\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('The confusion matrix is:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING MODEL FOR IAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model for IAM \n",
      "[[0.61565168 0.38434832]]\n",
      "Accurancy is:\n",
      "1.0\n",
      "The confusion matrix is:\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"The model for IAM \")\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts2, df2['label'], test_size=0.1, random_state=55, shuffle=False)\n",
    "#Ajustar los datos al modelo \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB().fit(X_train, y_train)\n",
    "#Evaluar  el modelo \n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "probability = model.predict_proba(X_test)\n",
    "print(probability)\n",
    "print('Accurancy is:')\n",
    "print(np.mean(predicted == y_test))\n",
    "#Evaluemos la matriz de confusiÃ³n\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('The confusion matrix is:')\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comparing the results from the exercise that we made by hand and the previous exercise (Lab2, 4)  are iqual. But comparing the results from the previous exercise (Lab2, 4) and this exercise we can infer the results are similars but in this notebook they include a normalization additional and thus these two results are not equal. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
